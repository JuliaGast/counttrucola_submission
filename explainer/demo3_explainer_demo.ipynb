{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53b1b7b3",
   "metadata": {},
   "source": [
    "# Demo: How to explain predictions for Rule-based Temporal Knowledge Graph Forecasting using CountTRuCoLa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a225e0b",
   "metadata": {},
   "source": [
    "## 0. Prerequesites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe807f9",
   "metadata": {},
   "source": [
    "\n",
    "* **Install** the required packages:\n",
    "  ```bash\n",
    "  pip install -r requirements.txt\n",
    "  ```\n",
    "  *Note:* The `requirements.txt` file is located one folder above this notebook. \n",
    "\n",
    "* **Input files** \n",
    "  Place all inputs in the folder:\n",
    "  ```\n",
    "  ../files/explanations/yourexperimentname/input\n",
    "  ```\n",
    "\n",
    "    * **Rules**:\n",
    "        * Filename must follow the pattern:  \n",
    "          ```\n",
    "          datasetname-whateveryouwant-id.txt\n",
    "          ```\n",
    "          Example: `tkgl-icews14-example-ids.txt`\n",
    "        * Rules can be generated, e.g., from **CountTRuCoLa** (stored in `../files/rules/`).\n",
    "        * Otherwise, Custom rules should be written one per line, with the format:  \n",
    "          ```\n",
    "          lmbda alpha phi rho kappa gamma F head_id(X,Y,T) <= body_id(X,Y,U)\n",
    "          ```\n",
    "          Example:  \n",
    "          ` 0   0.014492753623188404   0   0   0   1   F   89(X,Y,T) <= 6(X,Y,U) `\n",
    "\n",
    "    * **Quadruples**: (optional)\n",
    "        * Plain text file `quadruples.txt` with first line `subject rel object timestep`\n",
    "        * One quadruple per line: `subject relation object timestamp`\n",
    "        * Quadruple formats supported:\n",
    "            * **IDs**: `1 273 710 313` (example for `tkgl-icews14`)  \n",
    "            * **Wildcards (`x`)**:  \n",
    "                - `1 x 710 x` → all quadruples with subject=1 and object=710  \n",
    "                - `1 x x x`, `x x 710 x`, etc.  \n",
    "            * **Strings**:  \n",
    "                - `women x police x` → matches any quadruple with *women* in subject and *police* in object (no Match case)\n",
    "                - Example match: `'Women_(Australia)' Bring_lawsuit_against 'Police_(Australia)' 317`  \n",
    "        * If no quadruple file is provided, the user will be prompted to enter quadruple interactively.\n",
    "\n",
    "\n",
    "* **Output** \n",
    "  After running the Explainer, results are written to:  \n",
    "  ```\n",
    "  ../files/explanations/yourexperimentname/output\n",
    "  ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53777bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import os\n",
    "import explainer_utils\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"rule_based\")))\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "import rule_based.eval as eval\n",
    "import rule_based.utils as utils\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import webbrowser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6869903",
   "metadata": {},
   "source": [
    "## 1. User defined configurations\n",
    "Change this as required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42df21b",
   "metadata": {},
   "source": [
    "### 1.1 Configurations for the explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d55e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exp_name = 'example' # we added some example rules for illustration. replace this with your own rules.\n",
    "dataset_split = 'test' # which part of the dataset are the quadruples from? 'test' or 'val'\n",
    "\n",
    "plot_figures_flag=True\n",
    "recreate_figures = False #True # do you want to recreate the figures? If yes, all old figures will be deleted, if no, the old figures for exp_name will be reused\n",
    "\n",
    "explain_all_quads_flag = False # explain all quads in the val or test set, instead of quads from quadruples.txt. this might be slow if you have a large dataset\n",
    "max_rules_per_pred = 30 # how many rules should be shown per prediction? If there are more rules, the top ones will be shown based on their score.\n",
    "num_cpus= 1 # number of cpus to use for parallel processing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165a76e6",
   "metadata": {},
   "source": [
    "### 1.2 Configurations for the rule application. \n",
    "If you do not know what to do, leave them None. In that case, the default params will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d29c85fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you do not know what to do, leave them None, then the default params will be used.\n",
    "AGGREGATION_FUNCTION, NUM_TOP_RULES, AGGREGATION_DECAY, F_UNSEEN_NEGATIVES, Z_RULES_FACTOR, APPLY_WINDOW_SIZE, RULE_TYPE_Z_FLAG, RULE_TYPE_F_FLAG = None, None, None, None, None, None, None, None\n",
    "\n",
    "## Otherwise, change the values here:\n",
    "\n",
    "# ## a) rule aggregation\n",
    "# AGGREGATION_FUNCTION = \"noisyor\" # select from \"maxplus\" / \"noisyor\" / \"max\" / \n",
    "# NUM_TOP_RULES = 5 #  noisy-or top-h; stops adding predicting rules to a candidate of a query if already num_top_rules; -1 means no limit\n",
    "# # predicted the candidate; if all candidates are predicted by num_top_rules, rule\n",
    "# # application is stopped; can be used in conjunction with \"noisyor\" to achieve\n",
    "# AGGREGATION_DECAY = 0.8  # decay factor for the aggregation function; only used for \"noisyor\"; the second score is multiplied by decay, the third by decay^2 and so on; if set to 1, no decay is applied; \n",
    "\n",
    "# ## b) f and z-rules\n",
    "# RULE_TYPE_Z_FLAG = True  # do you want to use z-rules\n",
    "# RULE_TYPE_F_FLAG = True # do you want to use f-rules \n",
    "# F_UNSEEN_NEGATIVES = 30  # A constant added to the denominator when computing confidences for f-rules. \n",
    "# Z_RULES_FACTOR = 0.1 # A scaling factor Z ∈ [0, 1] applied to the score predicted by the z-rules.\n",
    "\n",
    "# # c) window size for rule applciation\n",
    "# APPLY_WINDOW_SIZE = -1 # how many previous interactions do we take into account for the rules (for apply) - recommend: set to -1, to use all timesteps; or set as large as possible\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b014a6",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Internal explainer setup steps\n",
    "\n",
    "Set all configurations. \n",
    "Do not change if you do not know what you are doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1c54c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully copied ..\\files\\explanations\\styles.css to ..\\files\\explanations\\example\\output\\styles.css.\n",
      "you decided to reuse the old figures which are stored in:  ..\\files\\explanations\\example\\output\\figures\n",
      "I will use the rules specified in the following file:\n",
      "..\\files\\explanations\\example\\input\\tkgl-icews14-example-ruleset-ids.txt\n",
      "Operating on dataset:  tkgl-icews14\n",
      "raw file found, skipping download\n",
      "Dataset directory is  c:\\Users\\jgasting\\PythonScripts\\counttrucola\\tgb/datasets\\tkgl_icews14\n",
      "loading processed file\n",
      "num_rels:  230\n",
      ">>> loading and indexing of dataset 2.711 seconds\n",
      ">>> average number of time steps for a triple: 1.804\n",
      ">>> checked order of time steps, everything is fine\n",
      "I will use rules and params from file tkgl-icews14-example-ruleset-ids.txt\n",
      "I will explain the quadruples specified in the following file:\n",
      "..\\files\\explanations\\example\\input\\quadruples.txt\n",
      "I will explain in total 320 quadruples.\n",
      "Namespace(params=None)\n",
      "---------------------\n",
      "parsed_options_dict:  {}\n",
      "Using dataset name from options_call: tkgl-icews14\n",
      "dataset_name:  tkgl-icews14\n",
      "DATASET_OVERRIDES:  {'tkgl-icews14': {'AGGREGATION_DECAY': 0.8, 'NUM_TOP_RULES': 10, 'RULE_TYPE_C': True, 'DATAPOINT_THRESHOLD_MULTI': 0, 'F_UNSEEN_NEGATIVES': 10, 'LEARN_WINDOW_SIZE': 50, 'RULE_UNSEEN_NEGATIVES': 30, 'Z_RULES_FACTOR': 0.1}, 'tkgl-yago': {'AGGREGATION_DECAY': 0.7, 'NUM_TOP_RULES': 5, 'RULE_TYPE_C': True, 'DATAPOINT_THRESHOLD_MULTI': 50, 'F_UNSEEN_NEGATIVES': 30, 'LEARN_WINDOW_SIZE': 30, 'RULE_UNSEEN_NEGATIVES': 30, 'Z_RULES_FACTOR': 0.1}, 'tkgl-wikiold': {'AGGREGATION_DECAY': 0.8, 'NUM_TOP_RULES': 10, 'RULE_TYPE_C': True, 'DATAPOINT_THRESHOLD_MULTI': 50, 'F_UNSEEN_NEGATIVES': 10, 'LEARN_WINDOW_SIZE': 3, 'RULE_UNSEEN_NEGATIVES': 1, 'Z_RULES_FACTOR': 0.1}, 'tkgl-smallpedia': {'AGGREGATION_DECAY': 0.4, 'NUM_TOP_RULES': 5, 'RULE_TYPE_C': True, 'DATAPOINT_THRESHOLD_MULTI': 10, 'F_UNSEEN_NEGATIVES': 30, 'LEARN_WINDOW_SIZE': 3, 'RULE_UNSEEN_NEGATIVES': 3, 'Z_RULES_FACTOR': 0}, 'tkgl-polecat': {'AGGREGATION_DECAY': 0.8, 'NUM_TOP_RULES': 10, 'RULE_TYPE_C': False, 'DATAPOINT_THRESHOLD_MULTI': 0, 'F_UNSEEN_NEGATIVES': 10, 'LEARN_WINDOW_SIZE': 150, 'RULE_UNSEEN_NEGATIVES': 30, 'Z_RULES_FACTOR': 0.1}, 'tkgl-icews18': {'AGGREGATION_DECAY': 0.8, 'NUM_TOP_RULES': 10, 'RULE_TYPE_C': True, 'DATAPOINT_THRESHOLD_MULTI': 50, 'F_UNSEEN_NEGATIVES': 10, 'LEARN_WINDOW_SIZE': 50, 'RULE_UNSEEN_NEGATIVES': 100, 'Z_RULES_FACTOR': 0.1}, 'tkgl-gdelt': {'AGGREGATION_DECAY': 0.8, 'NUM_TOP_RULES': 10, 'RULE_TYPE_C': False, 'DATAPOINT_THRESHOLD_MULTI': 0, 'F_UNSEEN_NEGATIVES': 10, 'LEARN_WINDOW_SIZE': 200, 'RULE_UNSEEN_NEGATIVES': 30, 'Z_RULES_FACTOR': 0.1}, 'tkgl-wikidata': {'AGGREGATION_DECAY': 0.8, 'NUM_TOP_RULES': 10, 'RULE_TYPE_C': True, 'DATAPOINT_THRESHOLD_MULTI': 0, 'F_UNSEEN_NEGATIVES': 10, 'LEARN_WINDOW_SIZE': 10, 'RULE_UNSEEN_NEGATIVES': 30, 'Z_RULES_FACTOR': 0.1}, 'tkgl-icews': {'AGGREGATION_DECAY': 0.8, 'NUM_TOP_RULES': 10, 'DATAPOINT_THRESHOLD_MULTI': 50, 'F_UNSEEN_NEGATIVES': 10, 'LEARN_WINDOW_SIZE': 50, 'RULE_UNSEEN_NEGATIVES': 100, 'Z_RULES_FACTOR': 0.1}}\n",
      "Found dataset overrides for tkgl-icews14\n",
      "Overwriting AGGREGATION_DECAY with 0.8 from DATASET_OVERRIDES for dataset tkgl-icews14\n",
      "Overwriting NUM_TOP_RULES with 10 from DATASET_OVERRIDES for dataset tkgl-icews14\n",
      "Overwriting RULE_TYPE_C with True from DATASET_OVERRIDES for dataset tkgl-icews14\n",
      "Overwriting DATAPOINT_THRESHOLD_MULTI with 0 from DATASET_OVERRIDES for dataset tkgl-icews14\n",
      "Overwriting F_UNSEEN_NEGATIVES with 10 from DATASET_OVERRIDES for dataset tkgl-icews14\n",
      "Overwriting LEARN_WINDOW_SIZE with 50 from DATASET_OVERRIDES for dataset tkgl-icews14\n",
      "Overwriting RULE_UNSEEN_NEGATIVES with 30 from DATASET_OVERRIDES for dataset tkgl-icews14\n",
      "Overwriting Z_RULES_FACTOR with 0.1 from DATASET_OVERRIDES for dataset tkgl-icews14\n",
      "overwriting options from config file and command line call with parsed options\n",
      "overwriting options from config file and command line call with options_call that were passed to main()\n",
      "Overwriting DATASET_NAME with tkgl-icews14\n",
      "Namespace(params=None)\n",
      "---------------------\n",
      "Options for the explainer:\n",
      "{'DATASET_NAME': 'tkgl-icews14', 'RANKINGS_PATH': 'default', 'LEARN_DATA_PATH': 'default', 'CREATE_LEARN_DATA_FLAG': True, 'LEARN_PARAMS_OPTION': 'learn', 'LOAD_PARAMS_FLAG': False, 'APPLY_RULES_FLAG': True, 'EVAL_VALSET_FLAG': True, 'EVAL_TESTSET_FLAG': True, 'NUM_CPUS': 1, 'DELETE_RANKINGS_FLAG': False, 'PLOT_FLAG': False, 'RULE_TYPE_C': True, 'RULE_UNSEEN_NEGATIVES': 30, 'LEARN_WINDOW_SIZE': 50, 'DATAPOINT_THRESHOLD_MULTI': 0, 'Z_RULES_FACTOR': 0.1, 'F_UNSEEN_NEGATIVES': 10, 'AGGREGATION_FUNCTION': 'noisyor', 'AGGREGATION_DECAY': 0.8, 'NUM_TOP_RULES': 10, 'RULE_TYPE_Z': True, 'RULE_TYPE_F': True, 'RULE_TYPE_CYC1_REC': True, 'RULE_TYPE_CYC1_NON_REC': True, 'EVAL_TYPE': 'random', 'MULTI_FLAG': True, 'SINGLE_FLAG': True, 'THRESHOLD_CORRECT_PREDICTIONS': 0, 'THRESHOLD_CONFIDENCE': 0, 'THRESHOLD_APPLY_CONFIDENCE': 0, 'C_THRESHOLD_CONFIDENCE': 0.001, 'C_RULE_RECURRENCY_ACTIVE': True, 'LARGE_DATA_HARDCODE_FLAG': None, 'VERY_LARGE_DATA_HARDCODE_FLAG': None, 'APPLY_WINDOW_SIZE': -1, 'Z_MIN_SUPPORT': 0, 'Z_MIN_CONFIDENCE': 0, 'Z_UNSEEN_NEGATIVES': 10, 'F_MIN_SUPPORT': 0, 'F_MIN_CONFIDENCE': 0, 'LMBDA_REG': 0, 'RR_OFFSET': -99}\n"
     ]
    }
   ],
   "source": [
    "# prepare paths\n",
    "in_folder, out_folder = explainer_utils.prepare_paths(exp_name, recreate_figures, jupyter_flag=True)\n",
    "\n",
    "# get the data from user input: what quadruples to explain? what dataset to use?\n",
    "dataset, dataset_name, testset_dict, path_rules, quadruples = explainer_utils.get_data_from_user_input(in_folder, dataset_split, explain_all_quads_flag)\n",
    "\n",
    "# set all options\n",
    "user_options = {\n",
    "    \"AGGREGATION_FUNCTION\": AGGREGATION_FUNCTION,\n",
    "    \"NUM_TOP_RULES\": NUM_TOP_RULES,\n",
    "    \"AGGREGATION_DECAY\": AGGREGATION_DECAY,\n",
    "    \"F_UNSEEN_NEGATIVES\": F_UNSEEN_NEGATIVES,\n",
    "    \"Z_RULES_FACTOR\": Z_RULES_FACTOR,\n",
    "    \"APPLY_WINDOW_SIZE\": APPLY_WINDOW_SIZE,\n",
    "    \"RULE_TYPE_Z\": RULE_TYPE_Z_FLAG,\n",
    "    \"RULE_TYPE_F\": RULE_TYPE_F_FLAG\n",
    "}\n",
    "\n",
    "options_explain = explainer_utils.set_options( user_options, num_cpus, dataset_name, config_path = os.path.join(os.path.dirname(os.getcwd()), \"rule_based\"))\n",
    "print(\"Options for the explainer:\")\n",
    "print(options_explain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7aab79",
   "metadata": {},
   "source": [
    "## 3. Explaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "998aac30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read rules and params from file ..\\files\\explanations\\example\\input\\tkgl-icews14-example-ruleset-ids.txt\n",
      "read 6 rules from file ..\\files\\explanations\\example\\input\\tkgl-icews14-example-ruleset-ids.txt\n",
      "MEM at beginning of apply 575\n",
      "gathering z-rule statistics ...\n",
      "... done with gathering z-rule statistics\n",
      "gather f-rule statistics ...\n",
      "\n",
      "MEM at beginning of f-rule aquisition: 576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 452/452 [00:01<00:00, 329.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... done with gathering f-rule statistics, found 100582 f-rules.\n",
      "MEM after f-rule aquisition: 892\n",
      "apply rules to the test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [00:02<00:00, 51.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEM at end of apply after deleting stuff 715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jgasting\\PythonScripts\\counttrucola\\explainer\\explainer_utils.py:690: RuntimeWarning: invalid value encountered in log10\n",
      "  normalized_score = np.log10(score) / np.log10(max_score + 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML file has been created with new rows: ..\\files\\explanations\\example\\output\\explanations_fancy.html\n",
      "You can find the explanations here:\n",
      "..\\files\\explanations\\example\\output\\explanations_fancy.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"..\\files\\explanations\\example\\output\\explanations_fancy.html\" target=\"_blank\">Open Explanations in Browser</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rules, rule_triple_dict = explainer_utils.explain(dataset,out_folder, dataset_split, path_rules=path_rules, options_explain=options_explain,\n",
    "                         max_rules_per_pred=max_rules_per_pred, plot_figures_flag=plot_figures_flag)\n",
    "\n",
    "print(\"You can find the explanations here:\")\n",
    "print( os.path.join(out_folder, \"explanations_fancy.html\"))\n",
    "# Construct the path to the HTML file (e.g., explanations.html in the output folder)\n",
    "html_file = os.path.join(out_folder, \"explanations_fancy.html\")\n",
    "\n",
    "# Display a clickable link in the notebook\n",
    "display(HTML(f'<a href=\"{html_file}\" target=\"_blank\">Open Explanations in Browser</a>'))\n",
    "\n",
    "\n",
    "webbrowser.open_new_tab(html_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d59c8a",
   "metadata": {},
   "source": [
    "## 4. Evaluation (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b0ec4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading negative test samples\n",
      ">>> starting evaluation for every triple, in the  test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "324it [00:00, 5452.37it/s]             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval mode: test\n",
      "mean mrr: 0.5973109131654383\n",
      "mean hits@1: 0.525\n",
      "mean hits@10: 0.725\n",
      "mean hits@100: 0.825\n",
      "time to evaluate: 0.6070351600646973\n",
      "Evaluation results on the requested quadruples with the given rules:\n",
      "mrr:  0.5973109131654383\n",
      "hits@1, hits@10, hits@100: 0.525, 0.725, 0.825\n"
     ]
    }
   ],
   "source": [
    "path_rankings = os.path.join(out_folder,'ranks.txt')\n",
    "mrr, hits10, hits1, hits100, mrrperrel,hits1perrel, _, _ = eval.evaluate(dataset, path_rankings, 0.01, evaluation_mode=dataset_split, eval_type='random', special_evalquads=quadruples)\n",
    "utils.write_ranksperrel(mrrperrel, hits1perrel, out_folder, dataset.dataset.name, 'val')\n",
    "\n",
    "print('Evaluation results on the requested quadruples with the given rules:')\n",
    "print('mrr: ', mrr)\n",
    "print(f'hits@1, hits@10, hits@100: {hits1}, {hits10}, {hits100}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rules",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
